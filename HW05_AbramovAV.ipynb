{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Домашняя работа к уроку 5\n",
    "### Студент: Абрамов А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Задание 1. Написать теггер на данных с русским языком:\n",
    "\n",
    "-проверить UnigramTagger, BigramTagger, TrigramTagger и их комбинации\n",
    "\n",
    "-написать свой теггер как на занятии, попробовать разные векторайзеры, добавить знание не только букв но и слов\n",
    "\n",
    "-сравнить все реализованные методы, сделать выводы  \n",
    "\n",
    "\n",
    "Задание 2. Проверить, насколько хорошо работает NER\n",
    "Данные брать из Index of /pub/named_entities\n",
    "\n",
    "-проверить NER из nltk/spacy/deeppavlov.\n",
    "\n",
    "-написать свой NER, попробовать разные подходы.\n",
    "\n",
    "а) передаём в сетку токен и его соседей.\n",
    "\n",
    "б) передаём в сетку только токен.\n",
    "\n",
    "в) свой вариант.\n",
    "\n",
    "-сравнить свои реализованные подходы на качество — вывести precision/recall/f1_score.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Q2YzVZLz1MMO",
    "outputId": "e643f779-0c1f-4697-ab0b-b5b59b9f7df4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘datasets’: File exists\n",
      "--2023-05-04 11:19:26--  https://www.labinform.ru/pub/named_entities/collection5.zip\n",
      "Resolving www.labinform.ru (www.labinform.ru)... 95.181.230.181\n",
      "Connecting to www.labinform.ru (www.labinform.ru)|95.181.230.181|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1899530 (1.8M) [application/zip]\n",
      "Saving to: ‘collection5.zip.2’\n",
      "\n",
      "collection5.zip.2   100%[===================>]   1.81M  7.59MB/s    in 0.2s    \n",
      "\n",
      "2023-05-04 11:19:27 (7.59 MB/s) - ‘collection5.zip.2’ saved [1899530/1899530]\n",
      "\n",
      "Archive:  collection5.zip\n",
      "replace ./datasets/Collection5/001.ann? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
     ]
    }
   ],
   "source": [
    "!mkdir datasets\n",
    "!wget https://www.labinform.ru/pub/named_entities/collection5.zip\n",
    "!unzip collection5.zip -d ./datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7sK-eeWB1-fn",
    "outputId": "4cdfe07d-f0e8-4541-d633-c9eecb3cb719"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/spacy/util.py:895: UserWarning: [W094] Model 'en_core_web_md' (2.2.0) specifies an under-constrained spaCy version requirement: >=2.2.0. This can lead to compatibility problems with older versions, or as new spaCy versions are released, because the model may say it's compatible when it's not. Consider changing the \"spacy_version\" in your meta.json to a version range, with a lower and upper pin. For example: >=3.5.2,<3.6.0\n",
      "  warnings.warn(warn_msg)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
      "[nltk_data]       date!\n",
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     /root/nltk_data...\n",
      "[nltk_data]   Package maxent_ne_chunker is already up-to-date!\n",
      "[nltk_data] Downloading package words to /root/nltk_data...\n",
      "[nltk_data]   Package words is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n",
    "\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import en_core_web_md\n",
    "import ru_core_news_lg\n",
    "\n",
    "import corus\n",
    "from corus import load_ne5\n",
    "from razdel import tokenize\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, GlobalAveragePooling1D, GlobalMaxPooling1D, Conv1D, GRU, LSTM, Dropout, Input\n",
    "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization\n",
    "from sklearn import model_selection, preprocessing, linear_model\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nltk.download('maxent_ne_chunker')\n",
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EM_ejTwE2Qnk"
   },
   "outputs": [],
   "source": [
    "dataset_for_nltk = []\n",
    "\n",
    "for filename in os.scandir(\"datasets/Collection5/\"):\n",
    "    if filename.is_file():\n",
    "        name, ext = os.path.splitext(filename.path)\n",
    "        if ext == \".txt\":\n",
    "          with(open(filename.path,\"r\",encoding='utf-8') as f):\n",
    "            text = f.read()\n",
    "            tokens = text.split()\n",
    "          \n",
    "          tagged_tokens = {}\n",
    "\n",
    "          with(open(name + \".ann\",\"r\",encoding='utf-8') as f):\n",
    "            for line in f:\n",
    "              parts = line.split()\n",
    "              tag = parts[1]\n",
    "              name = ' '.join(parts[4:])\n",
    "              tagged_tokens[name] = tag\n",
    "\n",
    "          dataset_for_nltk.append((text, tagged_tokens))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0MV_Ha37Pyqt",
    "outputId": "abd60c10-1b16-48a0-bd97-6397118b8d50"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'БРЯНСК': 'LOC', 'РИА Новости': 'MEDIA', 'Анна Сенина': 'PER', 'Андрей Пономарев': 'PER', 'Николая Денина': 'PER', 'Брянской области': 'LOC', 'Дмитрий Огнев': 'PER', 'Пономарев': 'PER', 'Иван Тимохин': 'PER', 'Брянской областной думой': 'ORG', 'Огнев': 'PER', 'Яблоко': 'ORG', 'ЛДПР': 'ORG', 'Михаилом Марченко': 'PER', 'Денина': 'PER', 'Вадима Потомского': 'PER', 'Пономарева': 'PER', 'Денин': 'PER', 'Верховном суде': 'ORG', 'Марченко': 'PER', 'Совете Федерации': 'ORG', 'Людмилу Нарусову': 'PER', 'Александр Горшков': 'PER', 'Лариса Погорелова': 'PER', 'Рашит Габдулвалеев': 'PER'}\n",
      "[('БРЯНСК', 'GPE'), ('Анна Сенина', 'PERSON'), ('Андрей Пономарев', 'PERSON'), ('Николая Денина', 'PERSON'), ('Дмитрий Огнев', 'PERSON'), ('Пономарев', 'PERSON'), ('Кроме', 'PERSON'), ('Пономарев', 'PERSON'), ('Таким', 'PERSON'), ('Вадима Потомского', 'PERSON'), ('Денин', 'PERSON'), ('Марченко', 'ORGANIZATION'), ('Совете Федерации', 'PERSON'), ('Людмилу Нарусову', 'PERSON'), ('Горшков', 'PERSON'), ('Лариса Погорелова', 'PERSON'), ('РИА Новости', 'ORGANIZATION')]\n"
     ]
    }
   ],
   "source": [
    "for entry in dataset_for_nltk:\n",
    "  pred = [(' '.join(c[0] for c in chunk), chunk.label() ) for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(entry[0]))) if hasattr(chunk, 'label')]\n",
    "  print(entry[1])\n",
    "  print(pred)\n",
    "  break\n",
    "\n",
    "# Работает довольно плохо"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Bh0o4NPAWK20",
    "outputId": "fb1f615e-522b-43dc-fb97-0fc6112a6b89"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span class=\"tex2jax_ignore\"><div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    БРЯНСК\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", 26 ноя — \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Анна Сенина\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". Экс-глава брянских &quot;яблочников&quot; \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Андрей Пономарев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", снявший свою кандидатуру с губернаторских выборов в поддержку единоросса \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Николая Денина\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", назначен исполняющим обязанности заместителя губернатора \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Брянской области\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ", сообщил \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " пресс-секретарь главы региона \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Дмитрий Огнев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>По его словам, \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Пономарев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " будет координировать деятельность органов власти в сфере экономики.</br></br>Кроме того, исполняющим обязанности заместителя губернатора стал \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Иван Тимохин\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", возглавивший аппарат администрации.</br></br>&quot;Губернатор уже произвел назначения, но кандидатуры заместителей по уставу должны быть согласованы \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Брянской областной думой\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot;, — сказал \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Огнев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Пономарев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", возглавлявший брянское отделение партии &quot;\n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Яблоко\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "&quot;, был выдвинут кандидатом в губернаторы на выборах, которые прошли 14 октября. Однако за несколько дней до выборов \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Пономарев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " вместе с кандидатом от \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    ЛДПР\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Михаилом Марченко\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " сняли свои кандидатуры. Таким образом, они поддержали единоросса \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Денина\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", который на тот момент был снят с выборов по решению областного суда, удовлетворившего иск коммуниста \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Вадима Потомского\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>Партийное бюро исключило \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Пономарева\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " из партии, сочтя его решение &quot;наносящим партии политический ущерб&quot;. Вскоре после этого \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Пономарев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " предположил, что большинство партийцев также покинут региональное отделение.</br></br>\n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Денин\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", восстановивший в \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Верховном суде\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       " статус кандидата губернатора, выиграл выборы и в результате политического соглашения назначил либерал-демократа \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Марченко\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " представителем региона в \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Совете Федерации\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       ". На посту сенатора он сменил \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Людмилу Нарусову\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br>Кадровые изменения в администрации региона последовали сразу же после переизбрания \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Денина\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ". После инаугурации губернатор не продлил контракты с главами транспортного и жилищно-коммунального департаментов \n",
       "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Брянской области\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
       "</mark>\n",
       ". Они лишились своих постов из-за нерешенных проблем в подведомственных отраслях.</br></br>На минувшей неделе свои посты покинули сразу три заместителя губернатора, с которыми глава региона не продлил договоры: \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Александр Горшков\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ", \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Лариса Погорелова\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       " и \n",
       "<mark class=\"entity\" style=\"background: #ddd; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    Рашит Габдулвалеев\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">PER</span>\n",
       "</mark>\n",
       ".</br></br></br>Читайте далее: &quot;Яблочник&quot;, снявшийся с брянских выборов, назначен и.о. замгубернатора | \n",
       "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em;\">\n",
       "    РИА Новости\n",
       "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
       "</mark>\n",
       "</br></div></span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "nlp = ru_core_news_lg.load()\n",
    "doc = nlp(dataset_for_nltk[0][0])\n",
    "displacy.render(doc, jupyter=True, style='ent')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZLw99t0gcnkl"
   },
   "outputs": [],
   "source": [
    "import locale\n",
    "locale.getpreferredencoding = lambda: \"UTF-8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7CJ11T1Cdv4P",
    "outputId": "b31c8a1a-efa1-4d44-c438-2754f0d5787a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LANG=en_US.UTF-8\n",
      "LANGUAGE=\n",
      "LC_CTYPE=\"en_US.UTF-8\"\n",
      "LC_NUMERIC=\"en_US.UTF-8\"\n",
      "LC_TIME=\"en_US.UTF-8\"\n",
      "LC_COLLATE=\"en_US.UTF-8\"\n",
      "LC_MONETARY=\"en_US.UTF-8\"\n",
      "LC_MESSAGES=\"en_US.UTF-8\"\n",
      "LC_PAPER=\"en_US.UTF-8\"\n",
      "LC_NAME=\"en_US.UTF-8\"\n",
      "LC_ADDRESS=\"en_US.UTF-8\"\n",
      "LC_TELEPHONE=\"en_US.UTF-8\"\n",
      "LC_MEASUREMENT=\"en_US.UTF-8\"\n",
      "LC_IDENTIFICATION=\"en_US.UTF-8\"\n",
      "LC_ALL=\n"
     ]
    }
   ],
   "source": [
    "!locale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6rQzSVUAYWsk"
   },
   "outputs": [],
   "source": [
    "def load_text_patched(path):\n",
    "    # do not convert \\r\\n to \\n\n",
    "    with open(path, newline='', encoding='utf-8') as file:\n",
    "        return file.read()\n",
    "\n",
    "dir = 'datasets/Collection5/'\n",
    "# load_ne5 do not accept encoding, but Colab sometimes fails to default to utf-8 for unknown reasons\n",
    "corus.ne5.load_text = load_text_patched\n",
    "records = load_ne5(dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CfAXxQksYrOD",
    "outputId": "c379aa25-419e-442c-a896-f9e3261a06c8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "datasets/Collection5/26_11_12e.txt\n",
      "datasets/Collection5/1152.txt\n",
      "datasets/Collection5/1107.txt\n",
      "datasets/Collection5/004.txt\n",
      "datasets/Collection5/443.txt\n",
      "datasets/Collection5/kamchatka.txt\n",
      "datasets/Collection5/last_54.txt\n",
      "datasets/Collection5/114.txt\n",
      "datasets/Collection5/242.txt\n",
      "datasets/Collection5/25_12_12d.txt\n",
      "datasets/Collection5/627.txt\n",
      "datasets/Collection5/021.txt\n",
      "datasets/Collection5/057.txt\n",
      "datasets/Collection5/1182.txt\n",
      "datasets/Collection5/1146.txt\n",
      "datasets/Collection5/457.txt\n",
      "datasets/Collection5/396.txt\n",
      "datasets/Collection5/28_11_12f.txt\n",
      "datasets/Collection5/272.txt\n",
      "datasets/Collection5/last_03.txt\n",
      "datasets/Collection5/118.txt\n",
      "datasets/Collection5/002.txt\n",
      "datasets/Collection5/157.txt\n",
      "datasets/Collection5/620.txt\n",
      "datasets/Collection5/last_15.txt\n",
      "datasets/Collection5/505.txt\n",
      "datasets/Collection5/048.txt\n",
      "datasets/Collection5/160.txt\n",
      "datasets/Collection5/413.txt\n",
      "datasets/Collection5/428.txt\n",
      "datasets/Collection5/581.txt\n",
      "datasets/Collection5/354.txt\n",
      "datasets/Collection5/611.txt\n",
      "datasets/Collection5/585.txt\n",
      "datasets/Collection5/010.txt\n",
      "datasets/Collection5/last_51.txt\n",
      "datasets/Collection5/136.txt\n",
      "datasets/Collection5/472.txt\n",
      "datasets/Collection5/328.txt\n",
      "datasets/Collection5/522.txt\n",
      "datasets/Collection5/292.txt\n",
      "datasets/Collection5/631.txt\n",
      "datasets/Collection5/1034.txt\n",
      "datasets/Collection5/567.txt\n",
      "datasets/Collection5/1001.txt\n",
      "datasets/Collection5/1017.txt\n",
      "datasets/Collection5/04_12_12h_corr.txt\n",
      "datasets/Collection5/504.txt\n",
      "datasets/Collection5/426.txt\n",
      "datasets/Collection5/399.txt\n",
      "datasets/Collection5/060.txt\n",
      "datasets/Collection5/006.txt\n",
      "datasets/Collection5/497.txt\n",
      "datasets/Collection5/286.txt\n",
      "datasets/Collection5/020.txt\n",
      "datasets/Collection5/240.txt\n",
      "datasets/Collection5/113.txt\n",
      "datasets/Collection5/2046.txt\n",
      "datasets/Collection5/080.txt\n",
      "datasets/Collection5/blokhin.txt\n",
      "datasets/Collection5/28_11_12i.txt\n",
      "datasets/Collection5/516.txt\n",
      "datasets/Collection5/1177.txt\n",
      "datasets/Collection5/421.txt\n",
      "datasets/Collection5/last_45.txt\n",
      "datasets/Collection5/395.txt\n",
      "datasets/Collection5/610.txt\n",
      "datasets/Collection5/last_41.txt\n",
      "datasets/Collection5/378.txt\n",
      "datasets/Collection5/630.txt\n",
      "datasets/Collection5/461.txt\n",
      "datasets/Collection5/302.txt\n",
      "datasets/Collection5/139.txt\n",
      "datasets/Collection5/1200.txt\n",
      "datasets/Collection5/last_38.txt\n",
      "datasets/Collection5/182.txt\n",
      "datasets/Collection5/1024.txt\n",
      "datasets/Collection5/last_56.txt\n",
      "datasets/Collection5/365.txt\n",
      "datasets/Collection5/464.txt\n",
      "datasets/Collection5/013.txt\n",
      "datasets/Collection5/154.txt\n",
      "datasets/Collection5/442.txt\n",
      "datasets/Collection5/last_35.txt\n",
      "datasets/Collection5/1038.txt\n",
      "datasets/Collection5/167.txt\n",
      "datasets/Collection5/1185.txt\n",
      "datasets/Collection5/216.txt\n",
      "datasets/Collection5/last_53.txt\n",
      "datasets/Collection5/10_01_13a.txt\n",
      "datasets/Collection5/1104.txt\n",
      "datasets/Collection5/23_11_12b.txt\n",
      "datasets/Collection5/2022.txt\n",
      "datasets/Collection5/115.txt\n",
      "datasets/Collection5/552.txt\n",
      "datasets/Collection5/070.txt\n",
      "datasets/Collection5/015 (!).txt\n",
      "datasets/Collection5/25_12_12c.txt\n",
      "datasets/Collection5/1145.txt\n",
      "datasets/Collection5/191.txt\n",
      "datasets/Collection5/012.txt\n",
      "datasets/Collection5/192.txt\n",
      "datasets/Collection5/224.txt\n",
      "datasets/Collection5/166.txt\n",
      "datasets/Collection5/265.txt\n",
      "datasets/Collection5/28_11_12j.txt\n",
      "datasets/Collection5/1120.txt\n",
      "datasets/Collection5/last_73.txt\n",
      "datasets/Collection5/1127.txt\n",
      "datasets/Collection5/410.txt\n",
      "datasets/Collection5/03_12_12a.txt\n",
      "datasets/Collection5/1151.txt\n",
      "datasets/Collection5/520.txt\n",
      "datasets/Collection5/324.txt\n",
      "datasets/Collection5/09_01_13d.txt\n",
      "datasets/Collection5/492.txt\n",
      "datasets/Collection5/618.txt\n",
      "datasets/Collection5/490.txt\n",
      "datasets/Collection5/339.txt\n",
      "datasets/Collection5/037.txt\n",
      "datasets/Collection5/565.txt\n",
      "datasets/Collection5/last_18.txt\n",
      "datasets/Collection5/09_01_13e.txt\n",
      "datasets/Collection5/124.txt\n",
      "datasets/Collection5/053.txt\n",
      "datasets/Collection5/1020.txt\n",
      "datasets/Collection5/550.txt\n",
      "datasets/Collection5/082.txt\n",
      "datasets/Collection5/1132.txt\n",
      "datasets/Collection5/26_11_12f.txt\n",
      "datasets/Collection5/196.txt\n",
      "datasets/Collection5/2009.txt\n",
      "datasets/Collection5/524.txt\n",
      "datasets/Collection5/last_10.txt\n",
      "datasets/Collection5/483.txt\n",
      "datasets/Collection5/2041.txt\n",
      "datasets/Collection5/383.txt\n",
      "datasets/Collection5/562.txt\n",
      "datasets/Collection5/613.txt\n",
      "datasets/Collection5/036.txt\n",
      "datasets/Collection5/241.txt\n",
      "datasets/Collection5/1191.txt\n",
      "datasets/Collection5/594.txt\n",
      "datasets/Collection5/last_63.txt\n",
      "datasets/Collection5/last_48.txt\n",
      "datasets/Collection5/2024.txt\n",
      "datasets/Collection5/1110.txt\n",
      "datasets/Collection5/159.txt\n",
      "datasets/Collection5/1188.txt\n",
      "datasets/Collection5/239.txt\n",
      "datasets/Collection5/530.txt\n",
      "datasets/Collection5/21_11_12i.txt\n",
      "datasets/Collection5/200.txt\n",
      "datasets/Collection5/09_01_13c.txt\n",
      "datasets/Collection5/356.txt\n",
      "datasets/Collection5/1125.txt\n",
      "datasets/Collection5/382.txt\n",
      "datasets/Collection5/last_72.txt\n",
      "datasets/Collection5/1036.txt\n",
      "datasets/Collection5/500.txt\n",
      "datasets/Collection5/22_11_12c.txt\n",
      "datasets/Collection5/247.txt\n",
      "datasets/Collection5/506.txt\n",
      "datasets/Collection5/116.txt\n",
      "datasets/Collection5/30_11_12i.txt\n",
      "datasets/Collection5/028.txt\n",
      "datasets/Collection5/2005.txt\n",
      "datasets/Collection5/367.txt\n",
      "datasets/Collection5/340.txt\n",
      "datasets/Collection5/277.txt\n",
      "datasets/Collection5/2001.txt\n",
      "datasets/Collection5/409.txt\n",
      "datasets/Collection5/067.txt\n",
      "datasets/Collection5/040.txt\n",
      "datasets/Collection5/1139.txt\n",
      "datasets/Collection5/259.txt\n",
      "datasets/Collection5/klinton.txt\n",
      "datasets/Collection5/1008.txt\n",
      "datasets/Collection5/494.txt\n",
      "datasets/Collection5/361.txt\n",
      "datasets/Collection5/591.txt\n",
      "datasets/Collection5/371.txt\n",
      "datasets/Collection5/1007.txt\n",
      "datasets/Collection5/27_11_12j.txt\n",
      "datasets/Collection5/569.txt\n",
      "datasets/Collection5/last_25.txt\n",
      "datasets/Collection5/393.txt\n",
      "datasets/Collection5/254.txt\n",
      "datasets/Collection5/218.txt\n",
      "datasets/Collection5/208.txt\n",
      "datasets/Collection5/473.txt\n",
      "datasets/Collection5/1118.txt\n",
      "datasets/Collection5/097.txt\n",
      "datasets/Collection5/439.txt\n",
      "datasets/Collection5/065.txt\n",
      "datasets/Collection5/355.txt\n",
      "datasets/Collection5/394.txt\n",
      "datasets/Collection5/158.txt\n",
      "datasets/Collection5/100.txt\n",
      "datasets/Collection5/1189.txt\n",
      "datasets/Collection5/1162.txt\n",
      "datasets/Collection5/318.txt\n",
      "datasets/Collection5/392.txt\n",
      "datasets/Collection5/095.txt\n",
      "datasets/Collection5/323.txt\n",
      "datasets/Collection5/005.txt\n",
      "datasets/Collection5/373.txt\n",
      "datasets/Collection5/303.txt\n",
      "datasets/Collection5/111.txt\n",
      "datasets/Collection5/27_11_12a.txt\n",
      "datasets/Collection5/235.txt\n",
      "datasets/Collection5/03_12_12c.txt\n",
      "datasets/Collection5/412.txt\n",
      "datasets/Collection5/2050.txt\n",
      "datasets/Collection5/1183.txt\n",
      "datasets/Collection5/599.txt\n",
      "datasets/Collection5/2014.txt\n",
      "datasets/Collection5/153.txt\n",
      "datasets/Collection5/063.txt\n",
      "datasets/Collection5/151.txt\n",
      "datasets/Collection5/181.txt\n",
      "datasets/Collection5/1100.txt\n",
      "datasets/Collection5/543.txt\n",
      "datasets/Collection5/353.txt\n",
      "datasets/Collection5/214.txt\n",
      "datasets/Collection5/1150.txt\n",
      "datasets/Collection5/532.txt\n",
      "datasets/Collection5/1000.txt\n",
      "datasets/Collection5/499.txt\n",
      "datasets/Collection5/lenoblast.txt\n",
      "datasets/Collection5/332.txt\n",
      "datasets/Collection5/22_11_12i.txt\n",
      "datasets/Collection5/1028.txt\n",
      "datasets/Collection5/276.txt\n",
      "datasets/Collection5/444.txt\n",
      "datasets/Collection5/1186.txt\n",
      "datasets/Collection5/248.txt\n",
      "datasets/Collection5/10_01_13i.txt\n",
      "datasets/Collection5/1124.txt\n",
      "datasets/Collection5/106.txt\n",
      "datasets/Collection5/612.txt\n",
      "datasets/Collection5/1105.txt\n",
      "datasets/Collection5/1169.txt\n",
      "datasets/Collection5/538.txt\n",
      "datasets/Collection5/374.txt\n",
      "datasets/Collection5/130.txt\n",
      "datasets/Collection5/194.txt\n",
      "datasets/Collection5/last_06.txt\n",
      "datasets/Collection5/487.txt\n",
      "datasets/Collection5/346.txt\n",
      "datasets/Collection5/1168.txt\n",
      "datasets/Collection5/014.txt\n",
      "datasets/Collection5/183.txt\n",
      "datasets/Collection5/267.txt\n",
      "datasets/Collection5/220.txt\n",
      "datasets/Collection5/341.txt\n",
      "datasets/Collection5/last_43.txt\n",
      "datasets/Collection5/440.txt\n",
      "datasets/Collection5/434.txt\n",
      "datasets/Collection5/201.txt\n",
      "datasets/Collection5/19_11_12h.txt\n",
      "datasets/Collection5/066.txt\n",
      "datasets/Collection5/04_12_12g.txt\n",
      "datasets/Collection5/564.txt\n",
      "datasets/Collection5/075.txt\n",
      "datasets/Collection5/last_02.txt\n",
      "datasets/Collection5/295.txt\n",
      "datasets/Collection5/2008.txt\n",
      "datasets/Collection5/140.txt\n",
      "datasets/Collection5/228.txt\n",
      "datasets/Collection5/018.txt\n",
      "datasets/Collection5/2010.txt\n",
      "datasets/Collection5/515.txt\n",
      "datasets/Collection5/30_11_12h.txt\n",
      "datasets/Collection5/588.txt\n",
      "datasets/Collection5/595.txt\n",
      "datasets/Collection5/251.txt\n",
      "datasets/Collection5/211.txt\n",
      "datasets/Collection5/372.txt\n",
      "datasets/Collection5/186.txt\n",
      "datasets/Collection5/305.txt\n",
      "datasets/Collection5/last_59.txt\n",
      "datasets/Collection5/315.txt\n",
      "datasets/Collection5/1049.txt\n",
      "datasets/Collection5/407.txt\n",
      "datasets/Collection5/389.txt\n",
      "datasets/Collection5/059.txt\n",
      "datasets/Collection5/362.txt\n",
      "datasets/Collection5/335.txt\n",
      "datasets/Collection5/29_11_12b.txt\n",
      "datasets/Collection5/1113.txt\n",
      "datasets/Collection5/090.txt\n",
      "datasets/Collection5/404.txt\n",
      "datasets/Collection5/1180.txt\n",
      "datasets/Collection5/2003.txt\n",
      "datasets/Collection5/045.txt\n",
      "datasets/Collection5/1196.txt\n",
      "datasets/Collection5/23_11_12d.txt\n",
      "datasets/Collection5/29_11_12a.txt\n",
      "datasets/Collection5/1133.txt\n",
      "datasets/Collection5/23_11_12e.txt\n",
      "datasets/Collection5/078.txt\n",
      "datasets/Collection5/576.txt\n",
      "datasets/Collection5/527.txt\n",
      "datasets/Collection5/333.txt\n",
      "datasets/Collection5/313.txt\n",
      "datasets/Collection5/22_11_12j.txt\n",
      "datasets/Collection5/180.txt\n",
      "datasets/Collection5/15_01_13b.txt\n",
      "datasets/Collection5/344.txt\n",
      "datasets/Collection5/199.txt\n",
      "datasets/Collection5/628.txt\n",
      "datasets/Collection5/1137.txt\n",
      "datasets/Collection5/03_12_12d.txt\n",
      "datasets/Collection5/146.txt\n",
      "datasets/Collection5/299.txt\n",
      "datasets/Collection5/231.txt\n",
      "datasets/Collection5/027.txt\n",
      "datasets/Collection5/508.txt\n",
      "datasets/Collection5/348.txt\n",
      "datasets/Collection5/334.txt\n",
      "datasets/Collection5/579.txt\n",
      "datasets/Collection5/2029.txt\n",
      "datasets/Collection5/1006.txt\n",
      "datasets/Collection5/253.txt\n",
      "datasets/Collection5/161.txt\n",
      "datasets/Collection5/592.txt\n",
      "datasets/Collection5/621.txt\n",
      "datasets/Collection5/377.txt\n",
      "datasets/Collection5/601.txt\n",
      "datasets/Collection5/582.txt\n",
      "datasets/Collection5/1161.txt\n",
      "datasets/Collection5/last_37.txt\n",
      "datasets/Collection5/493.txt\n",
      "datasets/Collection5/554.txt\n",
      "datasets/Collection5/314.txt\n",
      "datasets/Collection5/260.txt\n",
      "datasets/Collection5/297.txt\n",
      "datasets/Collection5/1144.txt\n",
      "datasets/Collection5/474.txt\n",
      "datasets/Collection5/398.txt\n",
      "datasets/Collection5/555 (!).txt\n",
      "datasets/Collection5/1009.txt\n",
      "datasets/Collection5/525.txt\n",
      "datasets/Collection5/558.txt\n",
      "datasets/Collection5/last_22.txt\n",
      "datasets/Collection5/1040.txt\n",
      "datasets/Collection5/219.txt\n",
      "datasets/Collection5/319.txt\n",
      "datasets/Collection5/026.txt\n",
      "datasets/Collection5/1033.txt\n",
      "datasets/Collection5/360.txt\n",
      "datasets/Collection5/1109.txt\n",
      "datasets/Collection5/144.txt\n",
      "datasets/Collection5/1039.txt\n",
      "datasets/Collection5/489.txt\n",
      "datasets/Collection5/064.txt\n",
      "datasets/Collection5/366.txt\n",
      "datasets/Collection5/593.txt\n",
      "datasets/Collection5/1012.txt\n",
      "datasets/Collection5/188.txt\n",
      "datasets/Collection5/last_46.txt\n",
      "datasets/Collection5/2023.txt\n",
      "datasets/Collection5/15_01_13e.txt\n",
      "datasets/Collection5/1134.txt\n",
      "datasets/Collection5/2043.txt\n",
      "datasets/Collection5/22_11_12g.txt\n",
      "datasets/Collection5/600.txt\n",
      "datasets/Collection5/sobjanin2.txt\n",
      "datasets/Collection5/1197.txt\n",
      "datasets/Collection5/1117.txt\n",
      "datasets/Collection5/2039.txt\n",
      "datasets/Collection5/512.txt\n",
      "datasets/Collection5/467.txt\n",
      "datasets/Collection5/1194.txt\n",
      "datasets/Collection5/202.txt\n",
      "datasets/Collection5/1181.txt\n",
      "datasets/Collection5/mvd.txt\n",
      "datasets/Collection5/27_11_12d.txt\n",
      "datasets/Collection5/252.txt\n",
      "datasets/Collection5/495.txt\n",
      "datasets/Collection5/376.txt\n",
      "datasets/Collection5/470.txt\n",
      "datasets/Collection5/056.txt\n",
      "datasets/Collection5/1106.txt\n",
      "datasets/Collection5/1102.txt\n",
      "datasets/Collection5/121.txt\n",
      "datasets/Collection5/296.txt\n",
      "datasets/Collection5/287.txt\n",
      "datasets/Collection5/517.txt\n",
      "datasets/Collection5/386.txt\n",
      "datasets/Collection5/1044.txt\n",
      "datasets/Collection5/329.txt\n",
      "datasets/Collection5/411.txt\n",
      "datasets/Collection5/419.txt\n",
      "datasets/Collection5/25_12_12e.txt\n",
      "datasets/Collection5/09_01_13a.txt\n",
      "datasets/Collection5/370.txt\n",
      "datasets/Collection5/293.txt\n",
      "datasets/Collection5/2049.txt\n",
      "datasets/Collection5/084.txt\n",
      "datasets/Collection5/071.txt\n",
      "datasets/Collection5/133.txt\n",
      "datasets/Collection5/578.txt\n",
      "datasets/Collection5/262.txt\n",
      "datasets/Collection5/1021.txt\n",
      "datasets/Collection5/1037.txt\n",
      "datasets/Collection5/316.txt\n",
      "datasets/Collection5/2015.txt\n",
      "datasets/Collection5/230.txt\n",
      "datasets/Collection5/568.txt\n",
      "datasets/Collection5/447.txt\n",
      "datasets/Collection5/301.txt\n",
      "datasets/Collection5/068.txt\n",
      "datasets/Collection5/si_tzjanpin.txt\n",
      "datasets/Collection5/1174.txt\n",
      "datasets/Collection5/325.txt\n",
      "datasets/Collection5/1187.txt\n",
      "datasets/Collection5/117.txt\n",
      "datasets/Collection5/465.txt\n",
      "datasets/Collection5/498.txt\n",
      "datasets/Collection5/424.txt\n",
      "datasets/Collection5/1046.txt\n",
      "datasets/Collection5/321.txt\n",
      "datasets/Collection5/438.txt\n",
      "datasets/Collection5/1031.txt\n",
      "datasets/Collection5/134.txt\n",
      "datasets/Collection5/400.txt\n",
      "datasets/Collection5/511.txt\n",
      "datasets/Collection5/596.txt\n",
      "datasets/Collection5/349.txt\n",
      "datasets/Collection5/1022.txt\n",
      "datasets/Collection5/112.txt\n",
      "datasets/Collection5/1003.txt\n",
      "datasets/Collection5/541.txt\n",
      "datasets/Collection5/1159.txt\n",
      "datasets/Collection5/last_13.txt\n",
      "datasets/Collection5/423.txt\n",
      "datasets/Collection5/435.txt\n",
      "datasets/Collection5/320.txt\n",
      "datasets/Collection5/271.txt\n",
      "datasets/Collection5/441.txt\n",
      "datasets/Collection5/350.txt\n",
      "datasets/Collection5/last_67.txt\n",
      "datasets/Collection5/450.txt\n",
      "datasets/Collection5/1166.txt\n",
      "datasets/Collection5/598 (!).txt\n",
      "datasets/Collection5/15_01_13a.txt\n",
      "datasets/Collection5/last_29.txt\n",
      "datasets/Collection5/255.txt\n",
      "datasets/Collection5/469.txt\n",
      "datasets/Collection5/last_34.txt\n",
      "datasets/Collection5/575.txt\n",
      "datasets/Collection5/488.txt\n",
      "datasets/Collection5/086.txt\n",
      "datasets/Collection5/243.txt\n",
      "datasets/Collection5/557.txt\n",
      "datasets/Collection5/2036.txt\n",
      "datasets/Collection5/047.txt\n",
      "datasets/Collection5/2028.txt\n",
      "datasets/Collection5/221.txt\n",
      "datasets/Collection5/2037.txt\n",
      "datasets/Collection5/1192.txt\n",
      "datasets/Collection5/345.txt\n",
      "datasets/Collection5/449.txt\n",
      "datasets/Collection5/Avtovaz.txt\n",
      "datasets/Collection5/184.txt\n",
      "datasets/Collection5/448.txt\n",
      "datasets/Collection5/055.txt\n",
      "datasets/Collection5/052.txt\n",
      "datasets/Collection5/518.txt\n",
      "datasets/Collection5/528.txt\n",
      "datasets/Collection5/223.txt\n",
      "datasets/Collection5/20_11_12b.txt\n",
      "datasets/Collection5/342.txt\n",
      "datasets/Collection5/semenenko.txt\n",
      "datasets/Collection5/217.txt\n",
      "datasets/Collection5/2016.txt\n",
      "datasets/Collection5/359.txt\n",
      "datasets/Collection5/430.txt\n",
      "datasets/Collection5/300.txt\n",
      "datasets/Collection5/04_12_12f.txt\n",
      "datasets/Collection5/031.txt\n",
      "datasets/Collection5/256.txt\n",
      "datasets/Collection5/1157.txt\n",
      "datasets/Collection5/502.txt\n",
      "datasets/Collection5/1149.txt\n",
      "datasets/Collection5/285.txt\n",
      "datasets/Collection5/016.txt\n",
      "datasets/Collection5/last_23.txt\n",
      "datasets/Collection5/073.txt\n",
      "datasets/Collection5/1195.txt\n",
      "datasets/Collection5/034.txt\n",
      "datasets/Collection5/2034.txt\n",
      "datasets/Collection5/1126.txt\n",
      "datasets/Collection5/176.txt\n",
      "datasets/Collection5/406.txt\n",
      "datasets/Collection5/481.txt\n",
      "datasets/Collection5/574.txt\n",
      "datasets/Collection5/1138.txt\n",
      "datasets/Collection5/357.txt\n",
      "datasets/Collection5/560.txt\n",
      "datasets/Collection5/110.txt\n",
      "datasets/Collection5/189.txt\n",
      "datasets/Collection5/623.txt\n",
      "datasets/Collection5/last_57.txt\n",
      "datasets/Collection5/289.txt\n",
      "datasets/Collection5/375.txt\n",
      "datasets/Collection5/108.txt\n",
      "datasets/Collection5/476.txt\n",
      "datasets/Collection5/2040.txt\n",
      "datasets/Collection5/433.txt\n",
      "datasets/Collection5/379.txt\n",
      "datasets/Collection5/244.txt\n",
      "datasets/Collection5/09_01_13h.txt\n",
      "datasets/Collection5/463.txt\n",
      "datasets/Collection5/1142.txt\n",
      "datasets/Collection5/1128.txt\n",
      "datasets/Collection5/shojgu1.txt\n",
      "datasets/Collection5/347.txt\n",
      "datasets/Collection5/586.txt\n",
      "datasets/Collection5/050.txt\n",
      "datasets/Collection5/03_12_12g.txt\n",
      "datasets/Collection5/1165.txt\n",
      "datasets/Collection5/178.txt\n",
      "datasets/Collection5/501.txt\n",
      "datasets/Collection5/2018.txt\n",
      "datasets/Collection5/529.txt\n",
      "datasets/Collection5/1179.txt\n",
      "datasets/Collection5/138.txt\n",
      "datasets/Collection5/last_66.txt\n",
      "datasets/Collection5/429.txt\n",
      "datasets/Collection5/577.txt\n",
      "datasets/Collection5/503.txt\n",
      "datasets/Collection5/1135.txt\n",
      "datasets/Collection5/308.txt\n",
      "datasets/Collection5/431.txt\n",
      "datasets/Collection5/last_16.txt\n",
      "datasets/Collection5/11_01_13e.txt\n",
      "datasets/Collection5/264.txt\n",
      "datasets/Collection5/1170.txt\n",
      "datasets/Collection5/269.txt\n",
      "datasets/Collection5/1043.txt\n",
      "datasets/Collection5/2002.txt\n",
      "datasets/Collection5/336.txt\n",
      "datasets/Collection5/331.txt\n",
      "datasets/Collection5/284.txt\n",
      "datasets/Collection5/193.txt\n",
      "datasets/Collection5/312.txt\n",
      "datasets/Collection5/21_11_12h.txt\n",
      "datasets/Collection5/453.txt\n",
      "datasets/Collection5/098.txt\n",
      "datasets/Collection5/122.txt\n",
      "datasets/Collection5/145.txt\n",
      "datasets/Collection5/478.txt\n",
      "datasets/Collection5/169.txt\n",
      "datasets/Collection5/548.txt\n",
      "datasets/Collection5/135.txt\n",
      "datasets/Collection5/141.txt\n",
      "datasets/Collection5/556.txt\n",
      "datasets/Collection5/452.txt\n",
      "datasets/Collection5/last_11.txt\n",
      "datasets/Collection5/1004.txt\n",
      "datasets/Collection5/475.txt\n",
      "datasets/Collection5/290.txt\n",
      "datasets/Collection5/last_33.txt\n",
      "datasets/Collection5/042.txt\n",
      "datasets/Collection5/204.txt\n",
      "datasets/Collection5/23_11_12c.txt\n",
      "datasets/Collection5/363.txt\n",
      "datasets/Collection5/1130.txt\n",
      "datasets/Collection5/rosobrnadzor.txt\n",
      "datasets/Collection5/2019.txt\n",
      "datasets/Collection5/626.txt\n",
      "datasets/Collection5/051.txt\n",
      "datasets/Collection5/27_11_12e.txt\n",
      "datasets/Collection5/278.txt\n",
      "datasets/Collection5/137.txt\n",
      "datasets/Collection5/last_49.txt\n",
      "datasets/Collection5/11_01_13b.txt\n",
      "datasets/Collection5/514.txt\n",
      "datasets/Collection5/1143.txt\n",
      "datasets/Collection5/2045.txt\n",
      "datasets/Collection5/1163.txt\n",
      "datasets/Collection5/069.txt\n",
      "datasets/Collection5/446.txt\n",
      "datasets/Collection5/023.txt\n",
      "datasets/Collection5/147.txt\n",
      "datasets/Collection5/425.txt\n",
      "datasets/Collection5/last_50.txt\n",
      "datasets/Collection5/455.txt\n",
      "datasets/Collection5/last_30_new.txt\n",
      "datasets/Collection5/2025.txt\n",
      "datasets/Collection5/last_69.txt\n",
      "datasets/Collection5/266.txt\n",
      "datasets/Collection5/1160.txt\n",
      "datasets/Collection5/1176.txt\n",
      "datasets/Collection5/019.txt\n",
      "datasets/Collection5/311.txt\n",
      "datasets/Collection5/007.txt\n",
      "datasets/Collection5/391.txt\n",
      "datasets/Collection5/1025.txt\n",
      "datasets/Collection5/last_39.txt\n",
      "datasets/Collection5/206.txt\n",
      "datasets/Collection5/1048.txt\n",
      "datasets/Collection5/04_02_13a_abdulatipov.txt\n",
      "datasets/Collection5/1014.txt\n",
      "datasets/Collection5/1010.txt\n",
      "datasets/Collection5/270.txt\n",
      "datasets/Collection5/10_01_13d.txt\n",
      "datasets/Collection5/351.txt\n",
      "datasets/Collection5/1050.txt\n",
      "datasets/Collection5/310.txt\n",
      "datasets/Collection5/last_47.txt\n",
      "datasets/Collection5/103.txt\n",
      "datasets/Collection5/025.txt\n",
      "datasets/Collection5/last_07_new.txt\n",
      "datasets/Collection5/572.txt\n",
      "datasets/Collection5/387.txt\n",
      "datasets/Collection5/294.txt\n",
      "datasets/Collection5/203.txt\n",
      "datasets/Collection5/229.txt\n",
      "datasets/Collection5/1023.txt\n",
      "datasets/Collection5/1131.txt\n",
      "datasets/Collection5/358.txt\n",
      "datasets/Collection5/150.txt\n",
      "datasets/Collection5/1154.txt\n",
      "datasets/Collection5/547.txt\n",
      "datasets/Collection5/074.txt\n",
      "datasets/Collection5/058.txt\n",
      "datasets/Collection5/288.txt\n",
      "datasets/Collection5/279.txt\n",
      "datasets/Collection5/101.txt\n",
      "datasets/Collection5/384.txt\n",
      "datasets/Collection5/last_55.txt\n",
      "datasets/Collection5/454.txt\n",
      "datasets/Collection5/261.txt\n",
      "datasets/Collection5/001.txt\n",
      "datasets/Collection5/142.txt\n",
      "datasets/Collection5/093.txt\n",
      "datasets/Collection5/119.txt\n",
      "datasets/Collection5/076.txt\n",
      "datasets/Collection5/shojgu6.txt\n",
      "datasets/Collection5/049.txt\n",
      "datasets/Collection5/1026.txt\n",
      "datasets/Collection5/559.txt\n",
      "datasets/Collection5/281.txt\n",
      "datasets/Collection5/1002.txt\n",
      "datasets/Collection5/last_17.txt\n",
      "datasets/Collection5/509.txt\n",
      "datasets/Collection5/198.txt\n",
      "datasets/Collection5/390.txt\n",
      "datasets/Collection5/317.txt\n",
      "datasets/Collection5/1119.txt\n",
      "datasets/Collection5/263.txt\n",
      "datasets/Collection5/19_11_12d.txt\n",
      "datasets/Collection5/616.txt\n",
      "datasets/Collection5/540.txt\n",
      "datasets/Collection5/last_26.txt\n",
      "datasets/Collection5/237.txt\n",
      "datasets/Collection5/551.txt\n",
      "datasets/Collection5/last_08.txt\n",
      "datasets/Collection5/last_75.txt\n",
      "datasets/Collection5/584 (!).txt\n",
      "datasets/Collection5/123.txt\n",
      "datasets/Collection5/250.txt\n",
      "datasets/Collection5/2042.txt\n",
      "datasets/Collection5/1198.txt\n",
      "datasets/Collection5/27_11_12c.txt\n",
      "datasets/Collection5/590.txt\n",
      "datasets/Collection5/156.txt\n",
      "datasets/Collection5/539.txt\n",
      "datasets/Collection5/last_01.txt\n",
      "datasets/Collection5/088.txt\n",
      "datasets/Collection5/1171.txt\n",
      "datasets/Collection5/14_01_13c.txt\n",
      "datasets/Collection5/mvd2.txt\n",
      "datasets/Collection5/482.txt\n",
      "datasets/Collection5/249.txt\n",
      "datasets/Collection5/038.txt\n",
      "datasets/Collection5/491.txt\n",
      "datasets/Collection5/615.txt\n",
      "datasets/Collection5/26_11_12b.txt\n",
      "datasets/Collection5/257.txt\n",
      "datasets/Collection5/last_32.txt\n",
      "datasets/Collection5/079.txt\n",
      "datasets/Collection5/275.txt\n",
      "datasets/Collection5/1101.txt\n",
      "datasets/Collection5/1158.txt\n",
      "datasets/Collection5/2020.txt\n",
      "datasets/Collection5/402.txt\n",
      "datasets/Collection5/1153.txt\n",
      "datasets/Collection5/148.txt\n",
      "datasets/Collection5/632.txt\n",
      "datasets/Collection5/1148.txt\n",
      "datasets/Collection5/2031.txt\n",
      "datasets/Collection5/25_12_12a.txt\n",
      "datasets/Collection5/2021.txt\n",
      "datasets/Collection5/28_11_12g.txt\n",
      "datasets/Collection5/227.txt\n",
      "datasets/Collection5/614.txt\n",
      "datasets/Collection5/126.txt\n",
      "datasets/Collection5/468.txt\n",
      "datasets/Collection5/535.txt\n",
      "datasets/Collection5/215.txt\n",
      "datasets/Collection5/326.txt\n",
      "datasets/Collection5/last_58.txt\n",
      "datasets/Collection5/20_11_12a.txt\n",
      "datasets/Collection5/last_21.txt\n",
      "datasets/Collection5/2035.txt\n",
      "datasets/Collection5/533 (!).txt\n",
      "datasets/Collection5/268.txt\n",
      "datasets/Collection5/195.txt\n",
      "datasets/Collection5/222.txt\n",
      "datasets/Collection5/22_11_12a.txt\n",
      "datasets/Collection5/30_11_12b.txt\n",
      "datasets/Collection5/460.txt\n",
      "datasets/Collection5/1032.txt\n",
      "datasets/Collection5/589.txt\n",
      "datasets/Collection5/2048.txt\n",
      "datasets/Collection5/061.txt\n",
      "datasets/Collection5/089.txt\n",
      "datasets/Collection5/abdulatipov.txt\n",
      "datasets/Collection5/017.txt\n",
      "datasets/Collection5/179.txt\n",
      "datasets/Collection5/403.txt\n",
      "datasets/Collection5/chaves.txt\n",
      "datasets/Collection5/last_04.txt\n",
      "datasets/Collection5/304.txt\n",
      "datasets/Collection5/213.txt\n",
      "datasets/Collection5/ryadovoy chelah.txt\n",
      "datasets/Collection5/last_36.txt\n",
      "datasets/Collection5/162.txt\n",
      "datasets/Collection5/619.txt\n",
      "datasets/Collection5/artjakov.txt\n",
      "datasets/Collection5/2047.txt\n",
      "datasets/Collection5/109.txt\n",
      "datasets/Collection5/041.txt\n",
      "datasets/Collection5/last_24.txt\n",
      "datasets/Collection5/22_11_12d.txt\n",
      "datasets/Collection5/1111.txt\n",
      "datasets/Collection5/427.txt\n",
      "datasets/Collection5/172.txt\n",
      "datasets/Collection5/1041.txt\n",
      "datasets/Collection5/last_40.txt\n",
      "datasets/Collection5/21_11_12c.txt\n",
      "datasets/Collection5/283.txt\n",
      "datasets/Collection5/last_65.txt\n",
      "datasets/Collection5/last_05.txt\n",
      "datasets/Collection5/163.txt\n",
      "datasets/Collection5/177.txt\n",
      "datasets/Collection5/486.txt\n",
      "datasets/Collection5/175.txt\n",
      "datasets/Collection5/1015.txt\n",
      "datasets/Collection5/1035.txt\n",
      "datasets/Collection5/072.txt\n",
      "datasets/Collection5/008.txt\n",
      "datasets/Collection5/last_19.txt\n",
      "datasets/Collection5/519.txt\n",
      "datasets/Collection5/1045.txt\n",
      "datasets/Collection5/1019.txt\n",
      "datasets/Collection5/2038.txt\n",
      "datasets/Collection5/309.txt\n",
      "datasets/Collection5/187.txt\n",
      "datasets/Collection5/185.txt\n",
      "datasets/Collection5/1178.txt\n",
      "datasets/Collection5/131.txt\n",
      "datasets/Collection5/143.txt\n",
      "datasets/Collection5/132.txt\n",
      "datasets/Collection5/2017.txt\n",
      "datasets/Collection5/1121.txt\n",
      "datasets/Collection5/last_42.txt\n",
      "datasets/Collection5/401.txt\n",
      "datasets/Collection5/last_71.txt\n",
      "datasets/Collection5/092.txt\n",
      "datasets/Collection5/322.txt\n",
      "datasets/Collection5/2044.txt\n",
      "datasets/Collection5/629.txt\n",
      "datasets/Collection5/107.txt\n",
      "datasets/Collection5/1147.txt\n",
      "datasets/Collection5/282.txt\n",
      "datasets/Collection5/1011.txt\n",
      "datasets/Collection5/2011.txt\n",
      "datasets/Collection5/046.txt\n",
      "datasets/Collection5/04_03_13a_sorokin.txt\n",
      "datasets/Collection5/280.txt\n",
      "datasets/Collection5/405.txt\n",
      "datasets/Collection5/083.txt\n",
      "datasets/Collection5/381.txt\n",
      "datasets/Collection5/085.txt\n",
      "datasets/Collection5/343.txt\n",
      "datasets/Collection5/1199.txt\n",
      "datasets/Collection5/338.txt\n",
      "datasets/Collection5/471.txt\n",
      "datasets/Collection5/327.txt\n",
      "datasets/Collection5/1112.txt\n",
      "datasets/Collection5/last_74.txt\n",
      "datasets/Collection5/190.txt\n",
      "datasets/Collection5/26_11_12c.txt\n",
      "datasets/Collection5/1030.txt\n",
      "datasets/Collection5/125.txt\n",
      "datasets/Collection5/571.txt\n",
      "datasets/Collection5/155.txt\n",
      "datasets/Collection5/1018.txt\n",
      "datasets/Collection5/210.txt\n",
      "datasets/Collection5/2007.txt\n",
      "datasets/Collection5/521.txt\n",
      "datasets/Collection5/368.txt\n",
      "datasets/Collection5/197.txt\n",
      "datasets/Collection5/496.txt\n",
      "datasets/Collection5/561.txt\n",
      "datasets/Collection5/maykl dzhekson.txt\n",
      "datasets/Collection5/462.txt\n",
      "datasets/Collection5/165.txt\n",
      "datasets/Collection5/510.txt\n",
      "datasets/Collection5/1029.txt\n",
      "datasets/Collection5/2026.txt\n",
      "datasets/Collection5/171.txt\n",
      "datasets/Collection5/087.txt\n",
      "datasets/Collection5/274.txt\n",
      "datasets/Collection5/043.txt\n",
      "datasets/Collection5/170.txt\n",
      "datasets/Collection5/617.txt\n",
      "datasets/Collection5/1167.txt\n",
      "datasets/Collection5/563.txt\n",
      "datasets/Collection5/1193.txt\n",
      "datasets/Collection5/622.txt\n",
      "datasets/Collection5/030.txt\n",
      "datasets/Collection5/shojgu4.txt\n",
      "datasets/Collection5/039.txt\n",
      "datasets/Collection5/033.txt\n",
      "datasets/Collection5/15_01_13f.txt\n",
      "datasets/Collection5/1047.txt\n",
      "datasets/Collection5/207.txt\n",
      "datasets/Collection5/385.txt\n",
      "datasets/Collection5/last_12.txt\n",
      "datasets/Collection5/127.txt\n",
      "datasets/Collection5/1155.txt\n",
      "datasets/Collection5/633.txt\n",
      "datasets/Collection5/553.txt\n",
      "datasets/Collection5/149.txt\n",
      "datasets/Collection5/544.txt\n",
      "datasets/Collection5/1013.txt\n",
      "datasets/Collection5/168.txt\n",
      "datasets/Collection5/534.txt\n",
      "datasets/Collection5/054.txt\n",
      "datasets/Collection5/009.txt\n",
      "datasets/Collection5/523.txt\n",
      "datasets/Collection5/shojgu3.txt\n",
      "datasets/Collection5/03_12_12h.txt\n",
      "datasets/Collection5/094.txt\n",
      "datasets/Collection5/337.txt\n",
      "datasets/Collection5/03_12_12b.txt\n",
      "datasets/Collection5/234.txt\n",
      "datasets/Collection5/last_52.txt\n",
      "datasets/Collection5/298.txt\n",
      "datasets/Collection5/2013.txt\n",
      "datasets/Collection5/022.txt\n",
      "datasets/Collection5/417.txt\n",
      "datasets/Collection5/291.txt\n",
      "datasets/Collection5/last_09.txt\n",
      "datasets/Collection5/20_11_12i.txt\n",
      "datasets/Collection5/1173.txt\n",
      "datasets/Collection5/625.txt\n",
      "datasets/Collection5/28_11_12a.txt\n",
      "datasets/Collection5/174.txt\n",
      "datasets/Collection5/035.txt\n",
      "datasets/Collection5/205.txt\n",
      "datasets/Collection5/14_01_13g.txt\n",
      "datasets/Collection5/1190.txt\n",
      "datasets/Collection5/233.txt\n",
      "datasets/Collection5/1108.txt\n",
      "datasets/Collection5/458.txt\n",
      "datasets/Collection5/029.txt\n",
      "datasets/Collection5/451.txt\n",
      "datasets/Collection5/246.txt\n",
      "datasets/Collection5/2006.txt\n",
      "datasets/Collection5/28_11_12h.txt\n",
      "datasets/Collection5/last_20.txt\n",
      "datasets/Collection5/245.txt\n",
      "datasets/Collection5/23_11_12a.txt\n",
      "datasets/Collection5/479.txt\n",
      "datasets/Collection5/236.txt\n",
      "datasets/Collection5/537.txt\n",
      "datasets/Collection5/445.txt\n",
      "datasets/Collection5/2032.txt\n",
      "datasets/Collection5/587.txt\n",
      "datasets/Collection5/last_61.txt\n",
      "datasets/Collection5/last_27.txt\n",
      "datasets/Collection5/129.txt\n",
      "datasets/Collection5/1141.txt\n",
      "datasets/Collection5/2027.txt\n",
      "datasets/Collection5/526.txt\n",
      "datasets/Collection5/003.txt\n",
      "datasets/Collection5/120.txt\n",
      "datasets/Collection5/225.txt\n",
      "datasets/Collection5/1122.txt\n",
      "datasets/Collection5/last_70.txt\n",
      "datasets/Collection5/14_01_13i.txt\n",
      "datasets/Collection5/1164.txt\n",
      "datasets/Collection5/032.txt\n",
      "datasets/Collection5/238.txt\n",
      "datasets/Collection5/209.txt\n",
      "datasets/Collection5/416.txt\n",
      "datasets/Collection5/1172.txt\n",
      "datasets/Collection5/602.txt\n",
      "datasets/Collection5/04_12_12d.txt\n",
      "datasets/Collection5/09_01_13.txt\n",
      "datasets/Collection5/173.txt\n",
      "datasets/Collection5/570.txt\n",
      "datasets/Collection5/104.txt\n",
      "datasets/Collection5/011.txt\n",
      "datasets/Collection5/096.txt\n",
      "datasets/Collection5/128.txt\n",
      "datasets/Collection5/484.txt\n",
      "datasets/Collection5/466.txt\n",
      "datasets/Collection5/last_68.txt\n",
      "datasets/Collection5/414.txt\n",
      "datasets/Collection5/chirkunov.txt\n",
      "datasets/Collection5/1114.txt\n",
      "datasets/Collection5/1016.txt\n",
      "datasets/Collection5/062.txt\n",
      "datasets/Collection5/1103.txt\n",
      "datasets/Collection5/1005.txt\n",
      "datasets/Collection5/408.txt\n",
      "datasets/Collection5/480.txt\n",
      "datasets/Collection5/232.txt\n",
      "datasets/Collection5/21_11_12j.txt\n",
      "datasets/Collection5/597.txt\n",
      "datasets/Collection5/09_01_13i.txt\n",
      "datasets/Collection5/last_14.txt\n",
      "datasets/Collection5/22_11_12h.txt\n",
      "datasets/Collection5/513.txt\n",
      "datasets/Collection5/397.txt\n",
      "datasets/Collection5/164.txt\n",
      "datasets/Collection5/459.txt\n",
      "datasets/Collection5/099.txt\n",
      "datasets/Collection5/436.txt\n",
      "datasets/Collection5/307.txt\n",
      "datasets/Collection5/531.txt\n",
      "datasets/Collection5/1027.txt\n",
      "datasets/Collection5/last_28.txt\n",
      "datasets/Collection5/102.txt\n",
      "datasets/Collection5/1184.txt\n",
      "datasets/Collection5/422.txt\n",
      "datasets/Collection5/081.txt\n",
      "datasets/Collection5/04_12_12b.txt\n",
      "datasets/Collection5/546.txt\n",
      "datasets/Collection5/1140.txt\n",
      "datasets/Collection5/2004.txt\n",
      "datasets/Collection5/542.txt\n",
      "datasets/Collection5/273.txt\n",
      "datasets/Collection5/044.txt\n",
      "datasets/Collection5/152.txt\n",
      "datasets/Collection5/507.txt\n",
      "datasets/Collection5/last_62.txt\n",
      "datasets/Collection5/23_11_12f.txt\n",
      "datasets/Collection5/last_60.txt\n",
      "datasets/Collection5/306.txt\n",
      "datasets/Collection5/1042.txt\n",
      "datasets/Collection5/2030.txt\n",
      "datasets/Collection5/418.txt\n",
      "datasets/Collection5/kuleshov.txt\n",
      "datasets/Collection5/1175.txt\n",
      "datasets/Collection5/last_31.txt\n",
      "datasets/Collection5/545.txt\n",
      "datasets/Collection5/369.txt\n",
      "datasets/Collection5/485.txt\n",
      "datasets/Collection5/226.txt\n",
      "datasets/Collection5/105.txt\n",
      "datasets/Collection5/2012.txt\n",
      "datasets/Collection5/388.txt\n",
      "datasets/Collection5/1136.txt\n",
      "datasets/Collection5/1123.txt\n",
      "datasets/Collection5/258.txt\n",
      "datasets/Collection5/380.txt\n",
      "datasets/Collection5/536.txt\n",
      "datasets/Collection5/583.txt\n",
      "datasets/Collection5/091.txt\n",
      "datasets/Collection5/1156.txt\n",
      "datasets/Collection5/20_11_12d.txt\n",
      "datasets/Collection5/352.txt\n",
      "datasets/Collection5/077.txt\n",
      "datasets/Collection5/1115.txt\n",
      "datasets/Collection5/364.txt\n",
      "datasets/Collection5/432.txt\n",
      "datasets/Collection5/uchitel.txt\n",
      "datasets/Collection5/212.txt\n",
      "datasets/Collection5/549.txt\n",
      "datasets/Collection5/624.txt\n",
      "datasets/Collection5/437.txt\n",
      "datasets/Collection5/415.txt\n",
      "datasets/Collection5/477.txt\n",
      "datasets/Collection5/420.txt\n",
      "datasets/Collection5/20_11_12c.txt\n",
      "datasets/Collection5/last_44.txt\n",
      "datasets/Collection5/last_64.txt\n",
      "datasets/Collection5/330.txt\n",
      "datasets/Collection5/1116.txt\n",
      "datasets/Collection5/turkmenija.txt\n"
     ]
    }
   ],
   "source": [
    "words_docs = []\n",
    "for ix, rec in enumerate(records):\n",
    "    words = []\n",
    "    for token in tokenize(rec.text):\n",
    "        type_ent = 'OUT'\n",
    "        for ent in rec.spans:\n",
    "            if (token.start >= ent.start) and (token.stop <= ent.stop):\n",
    "                type_ent = ent.type\n",
    "                break\n",
    "        words.append([token.text, type_ent])\n",
    "    words_docs.extend(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "bN2HQbtPYtz8"
   },
   "outputs": [],
   "source": [
    "df_words = pd.DataFrame(words_docs, columns=['word', 'tag'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oiApiWC5Y2NV"
   },
   "outputs": [],
   "source": [
    "train_x, valid_x, train_y, valid_y = model_selection.train_test_split(df_words['word'], df_words['tag'])\n",
    "\n",
    "# labelEncode целевую переменную\n",
    "encoder = preprocessing.LabelEncoder()\n",
    "train_y = encoder.fit_transform(train_y)\n",
    "valid_y = encoder.fit_transform(valid_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sKvMY9MOY6A9"
   },
   "outputs": [],
   "source": [
    "train_data = tf.data.Dataset.from_tensor_slices((train_x, train_y))\n",
    "valid_data = tf.data.Dataset.from_tensor_slices((valid_x, valid_y))\n",
    "\n",
    "train_data = train_data.batch(16)\n",
    "valid_data = valid_data.batch(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h2bCZ0MDY8Hd"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.AUTOTUNE\n",
    "\n",
    "train_data = train_data.cache().prefetch(buffer_size=AUTOTUNE)\n",
    "valid_data = valid_data.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fz_B9tMtY-hj"
   },
   "outputs": [],
   "source": [
    "def custom_standardization(input_data):\n",
    "    return input_data\n",
    "\n",
    "vocab_size = 30000\n",
    "seq_len = 128\n",
    "\n",
    "vectorize_layer = TextVectorization(\n",
    "    standardize=custom_standardization,\n",
    "    max_tokens=vocab_size,\n",
    "    output_mode='int',\n",
    "    # ngrams=(1, 5),\n",
    "    output_sequence_length=seq_len)\n",
    "\n",
    "# Make a text-only dataset (no labels) and call adapt to build the vocabulary.\n",
    "text_data = train_data.map(lambda x, y: x)\n",
    "vectorize_layer.adapt(text_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5U8s3Dl1ZEWd"
   },
   "outputs": [],
   "source": [
    "embedding_dim = 128\n",
    "\n",
    "class modelNER(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(modelNER, self).__init__()\n",
    "        self.emb = Embedding(vocab_size, embedding_dim)\n",
    "        self.gPool = GlobalMaxPooling1D()\n",
    "        self.fc1 = Dense(300, activation='relu')\n",
    "        self.fc2 = Dense(50, activation='relu')\n",
    "        self.fc3 = Dense(6, activation='softmax')\n",
    "\n",
    "    def call(self, x):\n",
    "        x = vectorize_layer(x)\n",
    "        x = self.emb(x)\n",
    "        pool_x = self.gPool(x)\n",
    "        \n",
    "        fc_x = self.fc1(pool_x)\n",
    "        fc_x = self.fc2(fc_x)\n",
    "        \n",
    "        concat_x = tf.concat([pool_x, fc_x], axis=1)\n",
    "        prob = self.fc3(concat_x)\n",
    "        return prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rf13IgCRZGRE"
   },
   "outputs": [],
   "source": [
    "model = modelNER()\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UYzPj3cIZJdt",
    "outputId": "ff78497e-f01c-4d0b-e998-4f991507158c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "12444/12444 [==============================] - 84s 7ms/step - loss: 0.1024 - acc: 0.9664 - val_loss: 0.2535 - val_acc: 0.8962\n",
      "Epoch 2/5\n",
      "12444/12444 [==============================] - 82s 7ms/step - loss: 0.0992 - acc: 0.9670 - val_loss: 0.2612 - val_acc: 0.8959\n",
      "Epoch 3/5\n",
      "12444/12444 [==============================] - 82s 7ms/step - loss: 0.0976 - acc: 0.9676 - val_loss: 0.2711 - val_acc: 0.8950\n",
      "Epoch 4/5\n",
      "12444/12444 [==============================] - 83s 7ms/step - loss: 0.0968 - acc: 0.9678 - val_loss: 0.2835 - val_acc: 0.8948\n",
      "Epoch 5/5\n",
      "12444/12444 [==============================] - 82s 7ms/step - loss: 0.0961 - acc: 0.9678 - val_loss: 0.2711 - val_acc: 0.9387\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f6498ab3880>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_data, validation_data=valid_data, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "29MfhpQXctkR",
    "outputId": "ede2f506-360a-42c2-8d61-be861a297049"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2074/2074 [==============================] - 6s 3ms/step\n",
      "Precision score 0.9188477989540954\n",
      "Recall score 0.7682516646226318\n",
      "F1 score 0.8281895170964603\n"
     ]
    }
   ],
   "source": [
    "y_pred1 = model.predict(valid_x)\n",
    "y_pred = np.argmax(y_pred1, axis=1)\n",
    "\n",
    "print(f'Precision score {precision_score(valid_y, y_pred , average=\"macro\")}')\n",
    "print(f'Recall score {recall_score(valid_y, y_pred , average=\"macro\")}')\n",
    "print(f'F1 score {f1_score(valid_y, y_pred , average=\"macro\")}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ax0WSjSweDC5"
   },
   "source": [
    "Одно слово (5 эпох):  \n",
    "Train Accuracy: 0.9678  \n",
    "Val Accuracy: 0.9387  \n",
    "Precision: 0.9188477989540954  \n",
    "Recall: 0.7682516646226318  \n",
    "F1: 0.8281895170964603  \n",
    "  \n",
    "С (1,5)-грамами (3 эпохи):  \n",
    "Train Accuracy: 0.9657  \n",
    "Val Accuracy: 0.9412  \n",
    "Precision: 0.9226781221438194  \n",
    "Recall: 0.7843320758632909  \n",
    "F1: 0.8371973641394906"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uItMJg6keNIt"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
