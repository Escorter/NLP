{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1270a2b9",
   "metadata": {},
   "source": [
    "### Домашняя работа к уроку 6\n",
    "### Студент: Абрамов А.В."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbd9611e",
   "metadata": {},
   "source": [
    "Взять ноутбук colab_text_classification_part1.ipynb который разбирали на занятии и добавить пункты которые мы пропустили \n",
    "1. Проверьте повысилось ли качество на стандартных подходах при лемматизации/и без неё\n",
    "2. Удалите/(замените на тег) из текстов сущности(имена, локации, что-то ещё). Запустите классификатор и модельки на сеточках\n",
    "3. Сделайте выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4b0582d5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:39:53.120986Z",
     "start_time": "2024-01-11T19:39:53.102793Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy import displacy\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "74eed141",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:31:41.392841Z",
     "start_time": "2024-01-11T19:31:40.862999Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size = 25000\n",
      "Test size = 25000\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"train.tsv\", delimiter=\"\\t\")\n",
    "test_df = pd.read_csv(\"test.tsv\", delimiter=\"\\t\")\n",
    "\n",
    "print('Train size = {}'.format(len(train_df)))\n",
    "print('Test size = {}'.format(len(test_df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0c2c531b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:31:42.789755Z",
     "start_time": "2024-01-11T19:31:42.782750Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.<br /><br />It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality. <br /><br />This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.<br /><br />It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.\n",
      "------------------\n",
      "This show comes up with interesting locations as fast as the travel channel. It is billed as reality but in actuality it is pure prime time soap opera. It's tries to use exotic locales as a facade to bring people into a phony contest & then proceeds to hook viewers on the contestants soap opera style.  It also borrows from an early CBS game show pioneer- Beat The Clock- by inventing situations for its contestants to try & overcome. Then it rewards the winner money. If they can spice it up with a little interaction between the characters, even better. While the game format is in slow motion versus Beat The Clock- the real accomplishment of this series is to escape reality.   This show has elements of several types of successful past programs. Reality television, hardly, but if your hooked on the contestants, locale or contest, this is your cup of tea. If your not, this entire series is as I say, drivel dripping with gravy. It is another show hiding behind the reality label which is the trend it started in 2000.  It is slick & well produced, so it might last a while yet. After all, so do re-runs of Gilligan's Island, Green Acres, The Beverly Hillbillies & The Brady Bunch. This just doesn't employ professional actors. The intelligence level is about the same.\n",
      "------------------\n"
     ]
    }
   ],
   "source": [
    "pattern = re.compile('<br\\s?\\/>|<br>')\n",
    "\n",
    "print(train_df['review'].iloc[1])\n",
    "print('------------------')\n",
    "\n",
    "print(pattern.subn(' ', train_df['review'].iloc[1])[0])\n",
    "print('------------------')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4ce928e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:31:45.935725Z",
     "start_time": "2024-01-11T19:31:45.928745Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "674aa612",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:31:47.148911Z",
     "start_time": "2024-01-11T19:31:47.134624Z"
    }
   },
   "outputs": [],
   "source": [
    "tokenizer = nltk.tokenize.WordPunctTokenizer()\n",
    "mystopwords = stopwords.words(\"english\") + ['the', 'a']\n",
    "\n",
    "def remove_punktuation(text):\n",
    "    return re.sub(r'[^\\w\\s\\d]', '', text)\n",
    "\n",
    "def lower_case(text):\n",
    "    text = str(text).lower()\n",
    "    return ' '.join(tokenizer.tokenize(text))\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = [w for w in text if w not in mystopwords]\n",
    "    return ' '.join(text)\n",
    "    \n",
    "def normalize(text):\n",
    "    text = remove_punktuation(text)\n",
    "    text = lower_case(text)\n",
    "    text = remove_stopwords(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d09b48d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:32:09.891516Z",
     "start_time": "2024-01-11T19:31:48.950744Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['review'] = train_df['review'].apply(normalize)\n",
    "test_df['review'] = test_df['review'].apply(normalize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "74821526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:40:40.943468Z",
     "start_time": "2024-01-11T19:40:40.935489Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "915bda9c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:41:10.575390Z",
     "start_time": "2024-01-11T19:41:08.462792Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>CountVectorizer()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "CountVectorizer()"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(train_df['review'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5a8ed63c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:42:03.723943Z",
     "start_time": "2024-01-11T19:42:03.712021Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1x120871 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 161 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.transform([train_df['review'].iloc[3]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b78ba764",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:42:50.208668Z",
     "start_time": "2024-01-11T19:42:50.191768Z"
    }
   },
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer()\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7e753efd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:43:19.544095Z",
     "start_time": "2024-01-11T19:43:15.190770Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;vectorizer&#x27;, CountVectorizer()),\n",
       "                (&#x27;classifier&#x27;, LogisticRegression())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">CountVectorizer</label><div class=\"sk-toggleable__content\"><pre>CountVectorizer()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('vectorizer', CountVectorizer()),\n",
       "                ('classifier', LogisticRegression())])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(train_df['review'], train_df['is_positive'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0263e401",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:43:48.906498Z",
     "start_time": "2024-01-11T19:43:46.974973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 86.77%\n"
     ]
    }
   ],
   "source": [
    "def eval_model(model, test_df):\n",
    "    preds = model.predict(test_df['review'])\n",
    "    print('Test accuracy = {:.2%}'.format(accuracy_score(test_df['is_positive'], preds)))\n",
    "    \n",
    "eval_model(model, test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b66af063",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:04.735103Z",
     "start_time": "2024-01-11T19:45:03.727826Z"
    }
   },
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm', disable=['parser'])\n",
    "\n",
    "docs = [doc for doc in nlp.pipe(train_df.review.values[:50])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7577fe3c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:05.535603Z",
     "start_time": "2024-01-11T19:45:05.527623Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dreamgirls dreamgirl B ORG\n",
      "despite despite O \n",
      "fistful fistful O \n",
      "tony tony O \n",
      "wins win O \n",
      "incredibly incredibly O \n",
      "weak weak O \n",
      "year year B DATE\n",
      "broadway broadway O \n",
      "never never O \n",
      "one one O \n",
      "would would O \n",
      "call call O \n",
      "jewel jewel B PERSON\n",
      "crown crown I PERSON\n",
      "stage stage O \n",
      "musicals musical O \n",
      "however however O \n",
      "say say O \n",
      "right right O \n",
      "cinematic cinematic O \n",
      "hands hand O \n",
      "could could O \n",
      "fleshed fleshed O \n",
      "polished polished O \n",
      "something something O \n",
      "worthwhile worthwhile O \n",
      "onscreen onscreen O \n",
      "unfortunately unfortunately O \n",
      "transfers transfer O \n",
      "screen screen O \n",
      "basically basically O \n",
      "slavishly slavishly O \n",
      "faithful faithful O \n",
      "version version O \n",
      "stage stage O \n",
      "hit hit O \n",
      "inherent inherent O \n",
      "weaknesses weakness O \n",
      "intact intact O \n",
      "first first B ORDINAL\n",
      "score score O \n",
      "never never O \n",
      "one one O \n",
      "strong strong O \n",
      "points point O \n",
      "production production O \n",
      "film film O \n",
      "change change O \n",
      "factor factor O \n",
      "lots lot O \n",
      "songs song O \n",
      "perhaps perhaps O \n",
      "many many O \n",
      "especially especially O \n",
      "memorable memorable O \n",
      "closest close O \n",
      "come come O \n",
      "catchy catchy O \n",
      "tunes tune O \n",
      "title title O \n",
      "song song O \n",
      "one one B TIME\n",
      "night night I TIME\n",
      "much much O \n",
      "acclaimed acclaimed O \n",
      "telling telling O \n",
      "going go O \n",
      "less less O \n",
      "great great O \n",
      "song song O \n",
      "dramatic dramatic O \n",
      "set set O \n",
      "piece piece O \n",
      "character character O \n",
      "effie effie O \n",
      "jennifer jennifer B PERSON\n",
      "hudson hudson I PERSON\n",
      "film film O \n",
      "slick slick O \n",
      "technically technically O \n",
      "wellproduced wellproduced O \n",
      "story story O \n",
      "characters character O \n",
      "surprisingly surprisingly O \n",
      "thin thin O \n",
      "lacking lack O \n",
      "resonance resonance O \n",
      "interest interest O \n",
      "opening opening O \n",
      "moments moment O \n",
      "watching watch O \n",
      "jamie jamie B PERSON\n",
      "foxxs foxxs I PERSON\n",
      "svengalilike svengalilike O \n",
      "manager manager O \n",
      "manipulate manipulate O \n",
      "acts act O \n",
      "top top O \n",
      "takes take O \n",
      "back back O \n",
      "seat seat O \n",
      "latter latter O \n",
      "portion portion O \n",
      "film film O \n",
      "story story O \n",
      "conveniently conveniently O \n",
      "tries try O \n",
      "cast cast O \n",
      "villain villain O \n",
      "despite despite O \n",
      "right right O \n",
      "business business O \n",
      "standpoint standpoint O \n",
      "good good O \n",
      "majority majority O \n",
      "film film O \n",
      "beyonce beyonce O \n",
      "knowles knowle O \n",
      "lovely lovely O \n",
      "sings sing O \n",
      "songs song O \n",
      "perfectly perfectly O \n",
      "well well O \n",
      "stuck stuck O \n",
      "character character O \n",
      "basically basically O \n",
      "surface surface O \n",
      "glitz glitz O \n",
      "anika anika O \n",
      "noni noni B PERSON\n",
      "rose rise O \n",
      "third third B ORDINAL\n",
      "member member O \n",
      "dreamgirls dreamgirls B PERSON\n",
      "trio trio I PERSON\n",
      "literally literally O \n",
      "nothing nothing O \n",
      "entire entire O \n",
      "film film O \n",
      "eddie eddie O \n",
      "murphy murphy B PERSON\n",
      "acquits acquit O \n",
      "well well O \n",
      "singer singer O \n",
      "obviously obviously O \n",
      "based base O \n",
      "james james B PERSON\n",
      "brown brown I PERSON\n",
      "role role O \n",
      "especially especially O \n",
      "meaty meaty O \n",
      "ultimately ultimately O \n",
      "little little O \n",
      "impact impact O \n",
      "foxx foxx O \n",
      "would would O \n",
      "seem seem O \n",
      "ideal ideal O \n",
      "casting casting O \n",
      "seems seem O \n",
      "oddly oddly O \n",
      "withdrawn withdraw O \n",
      "bored bored O \n",
      "films film O \n",
      "biggest big O \n",
      "selling selling O \n",
      "point point O \n",
      "surely surely O \n",
      "former former O \n",
      "american american B ORG\n",
      "idol idol I ORG\n",
      "contestantoscar contestantoscar O \n",
      "winner winner O \n",
      "jennifer jennifer B PERSON\n",
      "hudson hudson I PERSON\n",
      "central central O \n",
      "role role O \n",
      "effie effie O \n",
      "white white O \n",
      "temperamental temperamental O \n",
      "singer singer O \n",
      "gets get O \n",
      "booted boot O \n",
      "group group O \n",
      "makes make O \n",
      "triumphant triumphant O \n",
      "closing closing O \n",
      "act act O \n",
      "return return O \n",
      "effie effie B ORG\n",
      "always always O \n",
      "big big O \n",
      "problem problem O \n",
      "show show O \n",
      "movie movie O \n",
      "film film O \n",
      "obviously obviously O \n",
      "wants want O \n",
      "feel feel O \n",
      "sorry sorry O \n",
      "rather rather O \n",
      "hamhandedly hamhandedly O \n",
      "takes take O \n",
      "side side O \n",
      "never never O \n",
      "sure sure O \n",
      "character character O \n",
      "deserves deserve O \n",
      "kind kind O \n",
      "devotion devotion O \n",
      "start start O \n",
      "effie effie B ORG\n",
      "conducts conduct O \n",
      "part part O \n",
      "like like O \n",
      "obnoxious obnoxious O \n",
      "egotistical egotistical O \n",
      "selfcentered selfcentered O \n",
      "diva diva O \n",
      "interested interested O \n",
      "everyone everyone O \n",
      "else else O \n",
      "rather rather O \n",
      "much much O \n",
      "vested vested O \n",
      "interest interest O \n",
      "group group O \n",
      "part part O \n",
      "booted boot O \n",
      "group group O \n",
      "unprofessionalism unprofessionalism O \n",
      "bad bad O \n",
      "attitude attitude O \n",
      "charges charge O \n",
      "wellfounded wellfounde O \n",
      "stage stage O \n",
      "showfilm showfilm O \n",
      "seem seem O \n",
      "think think O \n",
      "effie effie B ORG\n",
      "cut cut O \n",
      "unlimited unlimited O \n",
      "slack slack O \n",
      "simply simply O \n",
      "great great O \n",
      "voice voice O \n",
      "even even O \n",
      "though though O \n",
      "film film O \n",
      "tries try O \n",
      "soften soften O \n",
      "effies effie O \n",
      "harder hard O \n",
      "edges edge O \n",
      "make make O \n",
      "likable likable O \n",
      "charges charge O \n",
      "still still O \n",
      "stand stand O \n",
      "story story O \n",
      "becomes become O \n",
      "manipulative manipulative O \n",
      "suggesting suggest O \n",
      "sympathy sympathy O \n",
      "unwed unwed O \n",
      "mother mother O \n",
      "struggling struggle O \n",
      "raise raise O \n",
      "daughter daughter O \n",
      "using use O \n",
      "implication implication O \n",
      "much much O \n",
      "like like O \n",
      "talent talent O \n",
      "card card O \n",
      "motherhood motherhood O \n",
      "immediately immediately O \n",
      "makes make O \n",
      "behavior behavior O \n",
      "excusable excusable O \n",
      "indeed indeed O \n",
      "big big O \n",
      "effort effort O \n",
      "film film O \n",
      "makes make O \n",
      "show show O \n",
      "effies effie O \n",
      "mothering mothering O \n",
      "tell tell O \n",
      "us we O \n",
      "include include O \n",
      "scene scene O \n",
      "barks barks O \n",
      "daughter daughter O \n",
      "unemployment unemployment O \n",
      "office office O \n",
      "insists insist O \n",
      "girl girl O \n",
      "father father O \n",
      "refuse refuse O \n",
      "look look O \n",
      "gainful gainful O \n",
      "employment employment O \n",
      "support support O \n",
      "since since O \n",
      "singing singing O \n",
      "knows know O \n",
      "hands hand O \n",
      "skillful skillful O \n",
      "actress actress O \n",
      "gaps gap O \n",
      "could could O \n",
      "perhaps perhaps O \n",
      "remedied remedied O \n",
      "technique technique O \n",
      "charisma charisma O \n",
      "unfortunately unfortunately O \n",
      "hudson hudson O \n",
      "actress actress O \n",
      "sings sing O \n",
      "well well O \n",
      "dialogdriven dialogdriven O \n",
      "moments moment O \n",
      "come come O \n",
      "naturally naturally O \n",
      "high high O \n",
      "emotional emotional O \n",
      "moments moment O \n",
      "effies effie O \n",
      "signature signature O \n",
      "moment moment O \n",
      "aforementioned aforementione O \n",
      "telling tell O \n",
      "number number O \n",
      "wellsung wellsung O \n",
      "hudson hudson O \n",
      "emotionally emotionally O \n",
      "flat flat O \n",
      "acting act O \n",
      "department department O \n",
      "effie effie B ORG\n",
      "supposed suppose O \n",
      "expressing express O \n",
      "rage rage O \n",
      "desperation desperation O \n",
      "predicament predicament O \n",
      "hudson hudson O \n",
      "comes come O \n",
      "cabaret cabaret O \n",
      "performer performer O \n",
      "belting belt O \n",
      "hot hot O \n",
      "number number O \n",
      "quite quite O \n",
      "emotional emotional O \n",
      "highlight highlight O \n",
      "one one O \n",
      "expects expect O \n",
      "latter latter O \n",
      "portion portion O \n",
      "film film O \n",
      "basically basically O \n",
      "predictable predictable O \n",
      "melange melange O \n",
      "events event O \n",
      "maneuver maneuver O \n",
      "foxx foxx O \n",
      "hudsons hudson O \n",
      "earlier early O \n",
      "position position O \n",
      "allow allow O \n",
      "strut strut O \n",
      "back back O \n",
      "lord lord O \n",
      "everyone everyone O \n",
      "foxxs foxxs O \n",
      "criminal criminal O \n",
      "offenses offenses O \n",
      "film film O \n",
      "undoubtedly undoubtedly O \n",
      "par par O \n",
      "course course O \n",
      "many many O \n",
      "struggling struggle O \n",
      "record record O \n",
      "producers producer O \n",
      "films film O \n",
      "seeming seem O \n",
      "implication implication O \n",
      "coming come O \n",
      "helped help O \n",
      "usher usher O \n",
      "disco disco O \n",
      "era era O \n",
      "rather rather O \n",
      "ridiculous ridiculous O \n",
      "mention mention O \n",
      "pretentious pretentious O \n",
      "condescending condescending O \n",
      "particularly particularly O \n",
      "coming come O \n",
      "film film O \n",
      "depth depth O \n",
      "puddle puddle O \n",
      "end end O \n",
      "result result O \n",
      "faithful faithful O \n",
      "rendition rendition O \n",
      "stage stage O \n",
      "hit hit O \n",
      "drained drain O \n",
      "emotion emotion O \n",
      "energy energy O \n",
      "anything anything O \n",
      "described describe O \n",
      "dynamic dynamic O \n"
     ]
    }
   ],
   "source": [
    "for token in docs[0]:\n",
    "    print(token.text, token.lemma_, token.ent_iob_, token.ent_type_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "7f88c526",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:07.964666Z",
     "start_time": "2024-01-11T19:45:07.951701Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c44e5f4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:11.207825Z",
     "start_time": "2024-01-11T19:45:11.190796Z"
    }
   },
   "outputs": [],
   "source": [
    "def lemmatized_words(text):\n",
    "    text_lem = [lemmatizer.lemmatize(word) for word in tokenizer.tokenize(text)]\n",
    "    return ' '.join(word for word in text_lem)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "7d416600",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:11.907810Z",
     "start_time": "2024-01-11T19:45:11.895842Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\User\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e4444f45",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:45:31.778990Z",
     "start_time": "2024-01-11T19:45:13.208621Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df['lemmatized'] = train_df['review'].apply(lemmatized_words)\n",
    "test_df['lemmatized'] = test_df['review'].apply(lemmatized_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "da4ceba2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-11T19:46:00.083376Z",
     "start_time": "2024-01-11T19:45:35.143780Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy = 87.64%\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
    "classifier = LogisticRegression()\n",
    "\n",
    "model = Pipeline([\n",
    "    ('vectorizer', vectorizer),\n",
    "    ('classifier', classifier)\n",
    "])\n",
    "\n",
    "model.fit(train_df['lemmatized'], train_df['is_positive'])\n",
    "\n",
    "eval_model(model, test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0fdc36",
   "metadata": {},
   "source": [
    "При использовании лемм accuracy выше, но не намного."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
